{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: h5py in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (5.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-gpu==1.14.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.24.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.1.7)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.17.2)\n",
      "Requirement already satisfied: setuptools in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: h5py in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.9.0)\n",
      "Requirement already satisfied: pandas_ml in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (0.6.1)\n",
      "Requirement already satisfied: pandas>=0.19.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from pandas_ml) (0.24.2)\n",
      "Requirement already satisfied: enum34 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from pandas_ml) (1.1.6)\n",
      "Requirement already satisfied: pytz>=2011k in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_ml) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_ml) (1.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_ml) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas>=0.19.0->pandas_ml) (1.12.0)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4\n",
    "!pip install tensorflow-gpu==1.14.0\n",
    "!pip install pandas_ml\n",
    "!conda install pandas==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import combine_images\n",
    "#from pandas_ml import ConfusionMatrix\n",
    "from PIL import Image\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sns.set()\n",
    "\n",
    "#importint the necessary lirbraries\n",
    "\n",
    "#import tensorflow.keras as kerasfrom __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import optimizers\n",
    "from keras.layers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from os import listdir\n",
    "import os\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, n_class, routings):\n",
    "    \"\"\"\n",
    "    A Capsule Network on MNIST.\n",
    "    :param input_shape: data shape, 3d, [width, height, channels]\n",
    "    :param n_class: number of classes\n",
    "    :param routings: number of routing iterations\n",
    "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
    "            `eval_model` can also be used for training.\n",
    "    \"\"\"\n",
    "    x = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Layer 1: Just a conventional Conv2D layer\n",
    "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "                             name='digitcaps')(primarycaps)\n",
    "\n",
    "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "    # If using tensorflow, this will not be necessary. :)\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "    # Decoder network.\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
    "    decoder.add(layers.Dense(1024, activation='relu'))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    # Models for training and evaluation (prediction)\n",
    "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "    # manipulate model\n",
    "    noise = layers.Input(shape=(n_class, 16))\n",
    "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "    return train_model, eval_model, manipulate_model\n",
    "\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 28, 28, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 20, 20, 256)  62464       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1152, 8)      0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1152, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "digitcaps (CapsuleLayer)        (None, 10, 16)       1474560     primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_4 (Mask)                   (None, 160)          0           digitcaps[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 10)           0           digitcaps[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 28, 28, 3)    3018544     mask_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 9,864,240\n",
      "Trainable params: 9,864,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define the model\n",
    "model, eval_model, manipulate_model = CapsNet(input_shape=(28, 28, 3),\n",
    "                                                  n_class=10,\n",
    "                                                  routings=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] splitting data\n"
     ]
    }
   ],
   "source": [
    "#Now rewriting the algorithm to preprocess about 500 images in my own pipeline\n",
    "#only do this if you have enough RAM\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (28, 28))\n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None\n",
    "\n",
    "image_list = []\n",
    "\n",
    "directory_root = '../dataset/train'\n",
    "imagePaths = list(paths.list_images(directory_root))\n",
    "imagePaths = imagePaths[0:-1:2]\n",
    "random.shuffle(imagePaths)\n",
    "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "\n",
    "batch_size = 16\n",
    "try:\n",
    "    for i in np.arange(0, len(imagePaths), batch_size):\n",
    "        batchPaths = imagePaths[i:i + batch_size]\n",
    "        batchLabels = labels[i: i + batch_size]\n",
    "        \n",
    "        for image in batchPaths:\n",
    "            image_list.append(convert_image_to_array(image))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "len(image_list), len(labels)\n",
    "\n",
    "np_image_list = np.array(image_list, dtype = np.float16) / 255.0\n",
    "print(f\"[INFO] splitting data\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9080, 28, 28, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_image_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_unclassfied = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = LabelBinarizer().fit_transform(y_test)\n",
    "y_train = LabelBinarizer().fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7264, 28, 28, 3), (1816, 28, 28, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7264, 28, 28, 3), (1816, 28, 28, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 3))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 3))\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, len(y_test)\n",
    "classNames = [str(x) for x in np.unique(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7264 samples, validate on 1816 samples\n",
      "Epoch 1/100\n",
      "7264/7264 [==============================] - 304s 42ms/step - loss: 0.4967 - capsnet_loss: 0.4869 - decoder_loss: 0.0252 - capsnet_acc: 0.3410 - val_loss: 0.3735 - val_capsnet_loss: 0.3642 - val_decoder_loss: 0.0237 - val_capsnet_acc: 0.5314\n",
      "\n",
      "Epoch 00001: val_capsnet_acc improved from -inf to 0.53139, saving model to ../models/latest_model.h5\n",
      "Epoch 2/100\n",
      "7264/7264 [==============================] - 291s 40ms/step - loss: 0.3184 - capsnet_loss: 0.3094 - decoder_loss: 0.0229 - capsnet_acc: 0.5874 - val_loss: 0.2719 - val_capsnet_loss: 0.2633 - val_decoder_loss: 0.0220 - val_capsnet_acc: 0.6773\n",
      "\n",
      "Epoch 00002: val_capsnet_acc improved from 0.53139 to 0.67731, saving model to ../models/latest_model.h5\n",
      "Epoch 3/100\n",
      "7264/7264 [==============================] - 299s 41ms/step - loss: 0.2651 - capsnet_loss: 0.2566 - decoder_loss: 0.0217 - capsnet_acc: 0.6725 - val_loss: 0.2352 - val_capsnet_loss: 0.2270 - val_decoder_loss: 0.0210 - val_capsnet_acc: 0.6938\n",
      "\n",
      "Epoch 00003: val_capsnet_acc improved from 0.67731 to 0.69383, saving model to ../models/latest_model.h5\n",
      "Epoch 4/100\n",
      "7264/7264 [==============================] - 297s 41ms/step - loss: 0.2365 - capsnet_loss: 0.2283 - decoder_loss: 0.0209 - capsnet_acc: 0.7115 - val_loss: 0.2338 - val_capsnet_loss: 0.2257 - val_decoder_loss: 0.0206 - val_capsnet_acc: 0.7219\n",
      "\n",
      "Epoch 00004: val_capsnet_acc improved from 0.69383 to 0.72192, saving model to ../models/latest_model.h5\n",
      "Epoch 5/100\n",
      "7264/7264 [==============================] - 294s 40ms/step - loss: 0.2131 - capsnet_loss: 0.2052 - decoder_loss: 0.0203 - capsnet_acc: 0.7485 - val_loss: 0.2216 - val_capsnet_loss: 0.2136 - val_decoder_loss: 0.0205 - val_capsnet_acc: 0.7351\n",
      "\n",
      "Epoch 00005: val_capsnet_acc improved from 0.72192 to 0.73513, saving model to ../models/latest_model.h5\n",
      "Epoch 6/100\n",
      "7264/7264 [==============================] - 294s 40ms/step - loss: 0.1972 - capsnet_loss: 0.1894 - decoder_loss: 0.0199 - capsnet_acc: 0.7689 - val_loss: 0.1921 - val_capsnet_loss: 0.1842 - val_decoder_loss: 0.0200 - val_capsnet_acc: 0.7627\n",
      "\n",
      "Epoch 00006: val_capsnet_acc improved from 0.73513 to 0.76267, saving model to ../models/latest_model.h5\n",
      "Epoch 7/100\n",
      "7264/7264 [==============================] - 296s 41ms/step - loss: 0.1789 - capsnet_loss: 0.1712 - decoder_loss: 0.0196 - capsnet_acc: 0.7949 - val_loss: 0.1936 - val_capsnet_loss: 0.1859 - val_decoder_loss: 0.0197 - val_capsnet_acc: 0.7742\n",
      "\n",
      "Epoch 00007: val_capsnet_acc improved from 0.76267 to 0.77423, saving model to ../models/latest_model.h5\n",
      "Epoch 8/100\n",
      "7264/7264 [==============================] - 294s 40ms/step - loss: 0.1628 - capsnet_loss: 0.1553 - decoder_loss: 0.0193 - capsnet_acc: 0.8270 - val_loss: 0.1841 - val_capsnet_loss: 0.1763 - val_decoder_loss: 0.0198 - val_capsnet_acc: 0.7770\n",
      "\n",
      "Epoch 00008: val_capsnet_acc improved from 0.77423 to 0.77698, saving model to ../models/latest_model.h5\n",
      "Epoch 9/100\n",
      "7264/7264 [==============================] - 301s 41ms/step - loss: 0.1518 - capsnet_loss: 0.1444 - decoder_loss: 0.0190 - capsnet_acc: 0.8455 - val_loss: 0.1941 - val_capsnet_loss: 0.1866 - val_decoder_loss: 0.0191 - val_capsnet_acc: 0.7632\n",
      "\n",
      "Epoch 00009: val_capsnet_acc did not improve from 0.77698\n",
      "Epoch 10/100\n",
      "7264/7264 [==============================] - 319s 44ms/step - loss: 0.1390 - capsnet_loss: 0.1317 - decoder_loss: 0.0186 - capsnet_acc: 0.8597 - val_loss: 0.1704 - val_capsnet_loss: 0.1628 - val_decoder_loss: 0.0193 - val_capsnet_acc: 0.8183\n",
      "\n",
      "Epoch 00010: val_capsnet_acc improved from 0.77698 to 0.81828, saving model to ../models/latest_model.h5\n",
      "Epoch 11/100\n",
      "7264/7264 [==============================] - 316s 43ms/step - loss: 0.1277 - capsnet_loss: 0.1205 - decoder_loss: 0.0184 - capsnet_acc: 0.8772 - val_loss: 0.1754 - val_capsnet_loss: 0.1680 - val_decoder_loss: 0.0190 - val_capsnet_acc: 0.8051\n",
      "\n",
      "Epoch 00011: val_capsnet_acc did not improve from 0.81828\n",
      "Epoch 12/100\n",
      "7264/7264 [==============================] - 310s 43ms/step - loss: 0.1164 - capsnet_loss: 0.1093 - decoder_loss: 0.0182 - capsnet_acc: 0.8936 - val_loss: 0.1564 - val_capsnet_loss: 0.1491 - val_decoder_loss: 0.0187 - val_capsnet_acc: 0.8161\n",
      "\n",
      "Epoch 00012: val_capsnet_acc did not improve from 0.81828\n",
      "Epoch 13/100\n",
      "7264/7264 [==============================] - 307s 42ms/step - loss: 0.1082 - capsnet_loss: 0.1011 - decoder_loss: 0.0180 - capsnet_acc: 0.9090 - val_loss: 0.1566 - val_capsnet_loss: 0.1494 - val_decoder_loss: 0.0186 - val_capsnet_acc: 0.8331\n",
      "\n",
      "Epoch 00013: val_capsnet_acc improved from 0.81828 to 0.83315, saving model to ../models/latest_model.h5\n",
      "Epoch 14/100\n",
      "7264/7264 [==============================] - 315s 43ms/step - loss: 0.1005 - capsnet_loss: 0.0936 - decoder_loss: 0.0177 - capsnet_acc: 0.9186 - val_loss: 0.1509 - val_capsnet_loss: 0.1436 - val_decoder_loss: 0.0186 - val_capsnet_acc: 0.8431\n",
      "\n",
      "Epoch 00014: val_capsnet_acc improved from 0.83315 to 0.84306, saving model to ../models/latest_model.h5\n",
      "Epoch 15/100\n",
      "7264/7264 [==============================] - 318s 44ms/step - loss: 0.0876 - capsnet_loss: 0.0807 - decoder_loss: 0.0175 - capsnet_acc: 0.9381 - val_loss: 0.1708 - val_capsnet_loss: 0.1636 - val_decoder_loss: 0.0184 - val_capsnet_acc: 0.8199\n",
      "\n",
      "Epoch 00015: val_capsnet_acc did not improve from 0.84306\n",
      "Epoch 16/100\n",
      "7264/7264 [==============================] - 327s 45ms/step - loss: 0.0800 - capsnet_loss: 0.0732 - decoder_loss: 0.0174 - capsnet_acc: 0.9478 - val_loss: 0.1609 - val_capsnet_loss: 0.1537 - val_decoder_loss: 0.0185 - val_capsnet_acc: 0.8453\n",
      "\n",
      "Epoch 00016: val_capsnet_acc improved from 0.84306 to 0.84526, saving model to ../models/latest_model.h5\n",
      "Epoch 17/100\n",
      "7264/7264 [==============================] - 318s 44ms/step - loss: 0.0737 - capsnet_loss: 0.0669 - decoder_loss: 0.0172 - capsnet_acc: 0.9576 - val_loss: 0.1368 - val_capsnet_loss: 0.1296 - val_decoder_loss: 0.0183 - val_capsnet_acc: 0.8508\n",
      "\n",
      "Epoch 00017: val_capsnet_acc improved from 0.84526 to 0.85077, saving model to ../models/latest_model.h5\n",
      "Epoch 18/100\n",
      "7264/7264 [==============================] - 321s 44ms/step - loss: 0.0668 - capsnet_loss: 0.0601 - decoder_loss: 0.0170 - capsnet_acc: 0.9665 - val_loss: 0.1540 - val_capsnet_loss: 0.1467 - val_decoder_loss: 0.0185 - val_capsnet_acc: 0.8254\n",
      "\n",
      "Epoch 00018: val_capsnet_acc did not improve from 0.85077\n",
      "Epoch 19/100\n",
      "7264/7264 [==============================] - 289s 40ms/step - loss: 0.0600 - capsnet_loss: 0.0535 - decoder_loss: 0.0168 - capsnet_acc: 0.9732 - val_loss: 0.1380 - val_capsnet_loss: 0.1310 - val_decoder_loss: 0.0181 - val_capsnet_acc: 0.8563\n",
      "\n",
      "Epoch 00019: val_capsnet_acc improved from 0.85077 to 0.85628, saving model to ../models/latest_model.h5\n",
      "Epoch 20/100\n",
      "7264/7264 [==============================] - 290s 40ms/step - loss: 0.0554 - capsnet_loss: 0.0488 - decoder_loss: 0.0167 - capsnet_acc: 0.9778 - val_loss: 0.1271 - val_capsnet_loss: 0.1200 - val_decoder_loss: 0.0181 - val_capsnet_acc: 0.8596\n",
      "\n",
      "Epoch 00020: val_capsnet_acc improved from 0.85628 to 0.85958, saving model to ../models/latest_model.h5\n",
      "Epoch 21/100\n",
      "7264/7264 [==============================] - 290s 40ms/step - loss: 0.0496 - capsnet_loss: 0.0432 - decoder_loss: 0.0165 - capsnet_acc: 0.9827 - val_loss: 0.1428 - val_capsnet_loss: 0.1356 - val_decoder_loss: 0.0182 - val_capsnet_acc: 0.8508\n",
      "\n",
      "Epoch 00021: val_capsnet_acc did not improve from 0.85958\n",
      "Epoch 22/100\n",
      "7264/7264 [==============================] - 293s 40ms/step - loss: 0.0443 - capsnet_loss: 0.0379 - decoder_loss: 0.0163 - capsnet_acc: 0.9847 - val_loss: 0.1464 - val_capsnet_loss: 0.1391 - val_decoder_loss: 0.0186 - val_capsnet_acc: 0.8546\n",
      "\n",
      "Epoch 00022: val_capsnet_acc did not improve from 0.85958\n",
      "Epoch 23/100\n",
      "7264/7264 [==============================] - 309s 43ms/step - loss: 0.0422 - capsnet_loss: 0.0358 - decoder_loss: 0.0162 - capsnet_acc: 0.9869 - val_loss: 0.1411 - val_capsnet_loss: 0.1340 - val_decoder_loss: 0.0180 - val_capsnet_acc: 0.8491\n",
      "\n",
      "Epoch 00023: val_capsnet_acc did not improve from 0.85958\n",
      "Epoch 24/100\n",
      "7264/7264 [==============================] - 293s 40ms/step - loss: 0.0361 - capsnet_loss: 0.0298 - decoder_loss: 0.0161 - capsnet_acc: 0.9891 - val_loss: 0.1241 - val_capsnet_loss: 0.1170 - val_decoder_loss: 0.0182 - val_capsnet_acc: 0.8623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_capsnet_acc improved from 0.85958 to 0.86233, saving model to ../models/latest_model.h5\n",
      "Epoch 25/100\n",
      "7264/7264 [==============================] - 288s 40ms/step - loss: 0.0292 - capsnet_loss: 0.0230 - decoder_loss: 0.0158 - capsnet_acc: 0.9934 - val_loss: 0.1288 - val_capsnet_loss: 0.1218 - val_decoder_loss: 0.0179 - val_capsnet_acc: 0.8596\n",
      "\n",
      "Epoch 00025: val_capsnet_acc did not improve from 0.86233\n",
      "Epoch 26/100\n",
      "7264/7264 [==============================] - 288s 40ms/step - loss: 0.0310 - capsnet_loss: 0.0249 - decoder_loss: 0.0157 - capsnet_acc: 0.9927 - val_loss: 0.1239 - val_capsnet_loss: 0.1168 - val_decoder_loss: 0.0181 - val_capsnet_acc: 0.8645\n",
      "\n",
      "Epoch 00026: val_capsnet_acc improved from 0.86233 to 0.86454, saving model to ../models/latest_model.h5\n",
      "Epoch 27/100\n",
      "7264/7264 [==============================] - 288s 40ms/step - loss: 0.0263 - capsnet_loss: 0.0202 - decoder_loss: 0.0156 - capsnet_acc: 0.9948 - val_loss: 0.1485 - val_capsnet_loss: 0.1414 - val_decoder_loss: 0.0180 - val_capsnet_acc: 0.8254\n",
      "\n",
      "Epoch 00027: val_capsnet_acc did not improve from 0.86454\n",
      "Epoch 28/100\n",
      "7264/7264 [==============================] - 329s 45ms/step - loss: 0.0281 - capsnet_loss: 0.0220 - decoder_loss: 0.0154 - capsnet_acc: 0.9952 - val_loss: 0.1454 - val_capsnet_loss: 0.1383 - val_decoder_loss: 0.0180 - val_capsnet_acc: 0.8436\n",
      "\n",
      "Epoch 00028: val_capsnet_acc did not improve from 0.86454\n",
      "Epoch 29/100\n",
      "7264/7264 [==============================] - 291s 40ms/step - loss: 0.0248 - capsnet_loss: 0.0188 - decoder_loss: 0.0153 - capsnet_acc: 0.9961 - val_loss: 0.1351 - val_capsnet_loss: 0.1281 - val_decoder_loss: 0.0180 - val_capsnet_acc: 0.8508\n",
      "\n",
      "Epoch 00029: val_capsnet_acc did not improve from 0.86454\n",
      "Epoch 30/100\n",
      "7264/7264 [==============================] - 294s 41ms/step - loss: 0.0226 - capsnet_loss: 0.0167 - decoder_loss: 0.0152 - capsnet_acc: 0.9959 - val_loss: 0.1387 - val_capsnet_loss: 0.1315 - val_decoder_loss: 0.0183 - val_capsnet_acc: 0.8607\n",
      "\n",
      "Epoch 00030: val_capsnet_acc did not improve from 0.86454\n",
      "Epoch 31/100\n",
      "7264/7264 [==============================] - 303s 42ms/step - loss: 0.0190 - capsnet_loss: 0.0131 - decoder_loss: 0.0149 - capsnet_acc: 0.9975 - val_loss: 0.1321 - val_capsnet_loss: 0.1251 - val_decoder_loss: 0.0178 - val_capsnet_acc: 0.8508\n",
      "\n",
      "Epoch 00031: val_capsnet_acc did not improve from 0.86454\n",
      "Epoch 32/100\n",
      "1170/7264 [===>..........................] - ETA: 4:13 - loss: 0.0198 - capsnet_loss: 0.0141 - decoder_loss: 0.0146 - capsnet_acc: 0.9983"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fca03c048809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m checkpoint = ModelCheckpoint(weight_path, monitor='val_capsnet_acc',\n\u001b[1;32m      9\u001b[0m                                            save_best_only=True, save_weights_only=True, verbose=1)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#fitting the model\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., 0.392],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "weight_path = '../models/latest_model.h5'\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_capsnet_acc',\n",
    "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
    "history = model.fit([x_train, y_train], [y_train, x_train], validation_data = [[x_test, y_test], [y_test, x_test]],  epochs = 100, batch_size = 10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = model.history.history['capsnet_acc'][:25]\n",
    "val_acc = model.history.history['val_capsnet_acc'][:25]\n",
    "loss = model.history.history['capsnet_loss'][:25]\n",
    "val_loss = model.history.history['val_capsnet_loss'][:25]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "#accuracy plot\n",
    "plt.plot(epochs, acc, color='green', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.savefig('./Plots/Accuracy_Capsulenet_Colored.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss plot\n",
    "plt.plot(epochs, loss, color='blue', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, color='red', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('./Plots/Loss_Capsulenet_Colored.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another way of evaluating the models \n",
    "eval_model.load_weights(\"../models/latest_model.h5\")\n",
    "y_test_uncoded = []\n",
    "for i in y_test:\n",
    "    y_test_uncoded.append(i.argmax())\n",
    "y_test_uncoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_recon = eval_model.predict(x_test, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = []\n",
    "for i in predictions:\n",
    "    y_preds.append(i.argmax())\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bacterial_spot</th>\n",
       "      <th>Early_blight</th>\n",
       "      <th>healthy</th>\n",
       "      <th>Late_blight</th>\n",
       "      <th>Leaf_Mold</th>\n",
       "      <th>mosaic_virus</th>\n",
       "      <th>Septoria_leaf_spot</th>\n",
       "      <th>spider_mite</th>\n",
       "      <th>Target_Spot</th>\n",
       "      <th>Yellow_Leaf_Curl</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.887387</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.830084</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.963989</td>\n",
       "      <td>0.906752</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.850575</td>\n",
       "      <td>0.864537</td>\n",
       "      <td>0.824055</td>\n",
       "      <td>0.863732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.867841</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.961326</td>\n",
       "      <td>0.909677</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.864537</td>\n",
       "      <td>0.835777</td>\n",
       "      <td>0.864479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.907834</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.864537</td>\n",
       "      <td>0.815423</td>\n",
       "      <td>0.864537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>217.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>0.864537</td>\n",
       "      <td>1816.000000</td>\n",
       "      <td>1816.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bacterial_spot  Early_blight     healthy  Late_blight   Leaf_Mold  \\\n",
       "f1-score         0.887387      0.605505    0.830084     0.800000    0.797753   \n",
       "precision        0.867841      0.616822    0.809783     0.888889    0.797753   \n",
       "recall           0.907834      0.594595    0.851429     0.727273    0.797753   \n",
       "support        217.000000    111.000000  175.000000    99.000000  178.000000   \n",
       "\n",
       "           mosaic_virus  Septoria_leaf_spot  spider_mite  Target_Spot  \\\n",
       "f1-score       0.798507            0.963989     0.906752     0.800000   \n",
       "precision      0.816794            0.961326     0.909677     0.866667   \n",
       "recall         0.781022            0.966667     0.903846     0.742857   \n",
       "support      137.000000          540.000000   156.000000    35.000000   \n",
       "\n",
       "           Yellow_Leaf_Curl  accuracy    macro avg  weighted avg  \n",
       "f1-score           0.850575  0.864537     0.824055      0.863732  \n",
       "precision          0.822222  0.864537     0.835777      0.864479  \n",
       "recall             0.880952  0.864537     0.815423      0.864537  \n",
       "support          168.000000  0.864537  1816.000000   1816.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = [\"Bacterial_spot\", \"Early_blight\",\"healthy\", \"Late_blight\", \"Leaf_Mold\", \"mosaic_virus\", \"Septoria_leaf_spot\", \"spider_mite\",\"Target_Spot\",\"Yellow_Leaf_Curl\"] \n",
    "prediction_matrix = classification_report(y_test_uncoded, y_preds, target_names= li, output_dict= True)\n",
    "predictions_df = pd.DataFrame(prediction_matrix)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please dont go below this Part of the Code, It is legacy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the weights from saved\n",
    "eval_model.load_weights(\"../models/best_weights_capsule_new_train.h5\")\n",
    "y_pred = []\n",
    "for i in range(0, x_test.shape[0]):\n",
    "    img = np.expand_dims(x_test[i], axis=0)\n",
    "    prediction, y_recon = eval_model.predict(img)\n",
    "    li = [\"Bacterial_spot\", \"Early_blight\",\"healthy\", \"Late_blight\", \"Leaf_Mold\", \"mosaic_virus\", \"Septoria_leaf_spot\", \"spider_mite\",\"Target_Spot\",\"Yellow_Leaf_Curl\"] \n",
    "    class_name = li[prediction.argmax()]\n",
    "    y_pred.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_unclassfied) == len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted           Bacterial_spot  Early_blight  Late_blight  Leaf_Mold  \\\n",
      "Actual                                                                     \n",
      "Bacterial_spot                 181             1            0          3   \n",
      "Early_blight                    10            71            0          4   \n",
      "Late_blight                      4             4            1          1   \n",
      "Leaf_Mold                        2             0           86         18   \n",
      "Septoria_leaf_spot               3             1            4        157   \n",
      "Target_Spot                      4             2            0          4   \n",
      "Yellow_Leaf_Curl                 9             0            0          1   \n",
      "healthy                          0             0            0          0   \n",
      "mosaic_virus                     0             0            3          6   \n",
      "spider_mite                      1             0            1          0   \n",
      "__all__                        214            79           95        194   \n",
      "\n",
      "Predicted           Septoria_leaf_spot  Target_Spot  Yellow_Leaf_Curl  \\\n",
      "Actual                                                                  \n",
      "Bacterial_spot                       9            0                 1   \n",
      "Early_blight                         4            0                 0   \n",
      "Late_blight                          2            1                 2   \n",
      "Leaf_Mold                            1            1                 1   \n",
      "Septoria_leaf_spot                   5            3                 3   \n",
      "Target_Spot                          2            1                11   \n",
      "Yellow_Leaf_Curl                   512            0                 3   \n",
      "healthy                              0            0                 2   \n",
      "mosaic_virus                         1           27                 2   \n",
      "spider_mite                          4            2               146   \n",
      "__all__                            540           35               171   \n",
      "\n",
      "Predicted           healthy  mosaic_virus  spider_mite  __all__  \n",
      "Actual                                                           \n",
      "Bacterial_spot            3             0            2      200  \n",
      "Early_blight              5             6            2      102  \n",
      "Late_blight             150             4            3      172  \n",
      "Leaf_Mold                 2             0            0      111  \n",
      "Septoria_leaf_spot        3             6            0      185  \n",
      "Target_Spot               0           118            9      151  \n",
      "Yellow_Leaf_Curl          0             4            0      529  \n",
      "healthy                   1             4          154      161  \n",
      "mosaic_virus              0             1            0       40  \n",
      "spider_mite               1             9            1      165  \n",
      "__all__                 165           152          171     1816  \n"
     ]
    }
   ],
   "source": [
    "#plotting the confusion matrix and evaluating the predictions\n",
    "confusion_matrix = ConfusionMatrix(y_test_unclassfied, y_pred)\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/pandas_ml/confusion_matrix/stats.py:60: FutureWarning: supplying multiple axes to axis is deprecated and will be removed in a future version.\n",
      "  num = df[df > 1].dropna(axis=[0, 1], thresh=1).applymap(lambda n: choose(n, 2)).sum().sum() - np.float64(nis2 * njs2) / n2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted           Bacterial_spot  Early_blight  Late_blight  Leaf_Mold  \\\n",
      "Actual                                                                     \n",
      "Bacterial_spot                 181             1            0          3   \n",
      "Early_blight                    10            71            0          4   \n",
      "Late_blight                      4             4            1          1   \n",
      "Leaf_Mold                        2             0           86         18   \n",
      "Septoria_leaf_spot               3             1            4        157   \n",
      "Target_Spot                      4             2            0          4   \n",
      "Yellow_Leaf_Curl                 9             0            0          1   \n",
      "healthy                          0             0            0          0   \n",
      "mosaic_virus                     0             0            3          6   \n",
      "spider_mite                      1             0            1          0   \n",
      "__all__                        214            79           95        194   \n",
      "\n",
      "Predicted           Septoria_leaf_spot  Target_Spot  Yellow_Leaf_Curl  \\\n",
      "Actual                                                                  \n",
      "Bacterial_spot                       9            0                 1   \n",
      "Early_blight                         4            0                 0   \n",
      "Late_blight                          2            1                 2   \n",
      "Leaf_Mold                            1            1                 1   \n",
      "Septoria_leaf_spot                   5            3                 3   \n",
      "Target_Spot                          2            1                11   \n",
      "Yellow_Leaf_Curl                   512            0                 3   \n",
      "healthy                              0            0                 2   \n",
      "mosaic_virus                         1           27                 2   \n",
      "spider_mite                          4            2               146   \n",
      "__all__                            540           35               171   \n",
      "\n",
      "Predicted           healthy  mosaic_virus  spider_mite  __all__  \n",
      "Actual                                                           \n",
      "Bacterial_spot            3             0            2      200  \n",
      "Early_blight              5             6            2      102  \n",
      "Late_blight             150             4            3      172  \n",
      "Leaf_Mold                 2             0            0      111  \n",
      "Septoria_leaf_spot        3             6            0      185  \n",
      "Target_Spot               0           118            9      151  \n",
      "Yellow_Leaf_Curl          0             4            0      529  \n",
      "healthy                   1             4          154      161  \n",
      "mosaic_virus              0             1            0       40  \n",
      "spider_mite               1             9            1      165  \n",
      "__all__                 165           152          171     1816  \n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.15583700440528633\n",
      "95% CI: (0.13944620818654518, 0.17334775448202377)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 0.9999999999999999\n",
      "Kappa: 0.05713298697428046\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                               Bacterial_spot Early_blight Late_blight  \\\n",
      "Population                                      1816         1816        1816   \n",
      "P: Condition positive                            200          102         172   \n",
      "N: Condition negative                           1616         1714        1644   \n",
      "Test outcome positive                            214           79          95   \n",
      "Test outcome negative                           1602         1737        1721   \n",
      "TP: True Positive                                181           71           1   \n",
      "TN: True Negative                               1583         1706        1550   \n",
      "FP: False Positive                                33            8          94   \n",
      "FN: False Negative                                19           31         171   \n",
      "TPR: (Sensitivity, hit rate, recall)           0.905     0.696078  0.00581395   \n",
      "TNR=SPC: (Specificity)                      0.979579     0.995333    0.942822   \n",
      "PPV: Pos Pred Value (Precision)             0.845794     0.898734   0.0105263   \n",
      "NPV: Neg Pred Value                          0.98814     0.982153    0.900639   \n",
      "FPR: False-out                             0.0204208   0.00466744   0.0571776   \n",
      "FDR: False Discovery Rate                   0.154206     0.101266    0.989474   \n",
      "FNR: Miss Rate                                 0.095     0.303922    0.994186   \n",
      "ACC: Accuracy                               0.971366     0.978524    0.854075   \n",
      "F1 score                                    0.874396      0.78453  0.00749064   \n",
      "MCC: Matthews correlation coefficient       0.858884      0.78042   -0.067549   \n",
      "Informedness                                0.884579     0.691411  -0.0513637   \n",
      "Markedness                                  0.833934     0.880887  -0.0888345   \n",
      "Prevalence                                  0.110132    0.0561674   0.0947137   \n",
      "LR+: Positive likelihood ratio               44.3176      149.135    0.101682   \n",
      "LR-: Negative likelihood ratio             0.0969804     0.305347     1.05448   \n",
      "DOR: Diagnostic odds ratio                   456.974      488.411    0.096429   \n",
      "FOR: False omission rate                   0.0118602    0.0178469   0.0993608   \n",
      "\n",
      "Classes                                Leaf_Mold Septoria_leaf_spot  \\\n",
      "Population                                  1816               1816   \n",
      "P: Condition positive                        111                185   \n",
      "N: Condition negative                       1705               1631   \n",
      "Test outcome positive                        194                540   \n",
      "Test outcome negative                       1622               1276   \n",
      "TP: True Positive                             18                  5   \n",
      "TN: True Negative                           1529               1096   \n",
      "FP: False Positive                           176                535   \n",
      "FN: False Negative                            93                180   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.162162           0.027027   \n",
      "TNR=SPC: (Specificity)                  0.896774            0.67198   \n",
      "PPV: Pos Pred Value (Precision)        0.0927835         0.00925926   \n",
      "NPV: Neg Pred Value                     0.942663           0.858934   \n",
      "FPR: False-out                          0.103226            0.32802   \n",
      "FDR: False Discovery Rate               0.907216           0.990741   \n",
      "FNR: Miss Rate                          0.837838           0.972973   \n",
      "ACC: Accuracy                           0.851872           0.606278   \n",
      "F1 score                                0.118033          0.0137931   \n",
      "MCC: Matthews correlation coefficient  0.0457068           -0.19918   \n",
      "Informedness                           0.0589364          -0.300993   \n",
      "Markedness                             0.0354469          -0.131807   \n",
      "Prevalence                             0.0611233           0.101872   \n",
      "LR+: Positive likelihood ratio           1.57095          0.0823945   \n",
      "LR-: Negative likelihood ratio           0.93428            1.44792   \n",
      "DOR: Diagnostic odds ratio               1.68145          0.0569055   \n",
      "FOR: False omission rate               0.0573366           0.141066   \n",
      "\n",
      "Classes                               Target_Spot Yellow_Leaf_Curl  \\\n",
      "Population                                   1816             1816   \n",
      "P: Condition positive                         151              529   \n",
      "N: Condition negative                        1665             1287   \n",
      "Test outcome positive                          35              171   \n",
      "Test outcome negative                        1781             1645   \n",
      "TP: True Positive                               1                3   \n",
      "TN: True Negative                            1631             1119   \n",
      "FP: False Positive                             34              168   \n",
      "FN: False Negative                            150              526   \n",
      "TPR: (Sensitivity, hit rate, recall)   0.00662252       0.00567108   \n",
      "TNR=SPC: (Specificity)                    0.97958         0.869464   \n",
      "PPV: Pos Pred Value (Precision)         0.0285714        0.0175439   \n",
      "NPV: Neg Pred Value                      0.915778         0.680243   \n",
      "FPR: False-out                          0.0204204         0.130536   \n",
      "FDR: False Discovery Rate                0.971429         0.982456   \n",
      "FNR: Miss Rate                           0.993377         0.994329   \n",
      "ACC: Accuracy                            0.898678         0.617841   \n",
      "F1 score                                0.0107527       0.00857143   \n",
      "MCC: Matthews correlation coefficient  -0.0277104        -0.194257   \n",
      "Informedness                           -0.0137979        -0.124865   \n",
      "Markedness                             -0.0556509        -0.302213   \n",
      "Prevalence                              0.0831498           0.2913   \n",
      "LR+: Positive likelihood ratio           0.324309        0.0434445   \n",
      "LR-: Negative likelihood ratio            1.01409          1.14361   \n",
      "DOR: Diagnostic odds ratio               0.319804        0.0379889   \n",
      "FOR: False omission rate                0.0842223         0.319757   \n",
      "\n",
      "Classes                                   healthy mosaic_virus spider_mite  \n",
      "Population                                   1816         1816        1816  \n",
      "P: Condition positive                         161           40         165  \n",
      "N: Condition negative                        1655         1776        1651  \n",
      "Test outcome positive                         165          152         171  \n",
      "Test outcome negative                        1651         1664        1645  \n",
      "TP: True Positive                               1            1           1  \n",
      "TN: True Negative                            1491         1625        1481  \n",
      "FP: False Positive                            164          151         170  \n",
      "FN: False Negative                            160           39         164  \n",
      "TPR: (Sensitivity, hit rate, recall)   0.00621118        0.025  0.00606061  \n",
      "TNR=SPC: (Specificity)                   0.900906     0.914977    0.897032  \n",
      "PPV: Pos Pred Value (Precision)        0.00606061   0.00657895  0.00584795  \n",
      "NPV: Neg Pred Value                      0.903089     0.976562    0.900304  \n",
      "FPR: False-out                          0.0990937    0.0850225    0.102968  \n",
      "FDR: False Discovery Rate                0.993939     0.993421    0.994152  \n",
      "FNR: Miss Rate                           0.993789        0.975    0.993939  \n",
      "ACC: Accuracy                            0.821586     0.895374    0.816079  \n",
      "F1 score                               0.00613497    0.0104167  0.00595238  \n",
      "MCC: Matthews correlation coefficient  -0.0918608   -0.0318103  -0.0953654  \n",
      "Informedness                           -0.0928825   -0.0600225  -0.0969073  \n",
      "Markedness                             -0.0908504   -0.0168586  -0.0938481  \n",
      "Prevalence                              0.0886564    0.0220264    0.090859  \n",
      "LR+: Positive likelihood ratio          0.0626799      0.29404   0.0588592  \n",
      "LR-: Negative likelihood ratio             1.1031       1.0656     1.10803  \n",
      "DOR: Diagnostic odds ratio              0.0568216     0.275938   0.0531205  \n",
      "FOR: False omission rate                 0.096911    0.0234375    0.099696  \n"
     ]
    }
   ],
   "source": [
    "confusion_matrix.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Bacterial_spot</th>\n",
       "      <th>Early_blight</th>\n",
       "      <th>Late_blight</th>\n",
       "      <th>Leaf_Mold</th>\n",
       "      <th>Septoria_leaf_spot</th>\n",
       "      <th>Target_Spot</th>\n",
       "      <th>Yellow_Leaf_Curl</th>\n",
       "      <th>healthy</th>\n",
       "      <th>mosaic_virus</th>\n",
       "      <th>spider_mite</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bacterial_spot</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Early_blight</th>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Late_blight</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leaf_Mold</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Septoria_leaf_spot</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target_Spot</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yellow_Leaf_Curl</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosaic_virus</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spider_mite</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted           Bacterial_spot  Early_blight  Late_blight  Leaf_Mold  \\\n",
       "Actual                                                                     \n",
       "Bacterial_spot                 181             1            0          3   \n",
       "Early_blight                    10            71            0          4   \n",
       "Late_blight                      4             4            1          1   \n",
       "Leaf_Mold                        2             0           86         18   \n",
       "Septoria_leaf_spot               3             1            4        157   \n",
       "Target_Spot                      4             2            0          4   \n",
       "Yellow_Leaf_Curl                 9             0            0          1   \n",
       "healthy                          0             0            0          0   \n",
       "mosaic_virus                     0             0            3          6   \n",
       "spider_mite                      1             0            1          0   \n",
       "\n",
       "Predicted           Septoria_leaf_spot  Target_Spot  Yellow_Leaf_Curl  \\\n",
       "Actual                                                                  \n",
       "Bacterial_spot                       9            0                 1   \n",
       "Early_blight                         4            0                 0   \n",
       "Late_blight                          2            1                 2   \n",
       "Leaf_Mold                            1            1                 1   \n",
       "Septoria_leaf_spot                   5            3                 3   \n",
       "Target_Spot                          2            1                11   \n",
       "Yellow_Leaf_Curl                   512            0                 3   \n",
       "healthy                              0            0                 2   \n",
       "mosaic_virus                         1           27                 2   \n",
       "spider_mite                          4            2               146   \n",
       "\n",
       "Predicted           healthy  mosaic_virus  spider_mite  \n",
       "Actual                                                  \n",
       "Bacterial_spot            3             0            2  \n",
       "Early_blight              5             6            2  \n",
       "Late_blight             150             4            3  \n",
       "Leaf_Mold                 2             0            0  \n",
       "Septoria_leaf_spot        3             6            0  \n",
       "Target_Spot               0           118            9  \n",
       "Yellow_Leaf_Curl          0             4            0  \n",
       "healthy                   1             4          154  \n",
       "mosaic_virus              0             1            0  \n",
       "spider_mite               1             9            1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix.to_dataframe().to_csv(\"./Results/confusion_matrix_colored.csv\")\n",
    "confusion_matrix.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Accuracy', 0.17015418502202642),\n",
       "             ('95% CI', (0.15313970056026627, 0.18824124883536253)),\n",
       "             ('No Information Rate', 'ToDo'),\n",
       "             ('P-Value [Acc > NIR]', 0.9999999999999999),\n",
       "             ('Kappa', 0.07430898197435461),\n",
       "             (\"Mcnemar's Test P-Value\", 'ToDo')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix.stats_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classes</th>\n",
       "      <th>Bacterial_spot</th>\n",
       "      <th>Early_blight</th>\n",
       "      <th>Late_blight</th>\n",
       "      <th>Leaf_Mold</th>\n",
       "      <th>Septoria_leaf_spot</th>\n",
       "      <th>Target_Spot</th>\n",
       "      <th>Yellow_Leaf_Curl</th>\n",
       "      <th>healthy</th>\n",
       "      <th>mosaic_virus</th>\n",
       "      <th>spider_mite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P: Condition positive</th>\n",
       "      <td>239</td>\n",
       "      <td>96</td>\n",
       "      <td>187</td>\n",
       "      <td>102</td>\n",
       "      <td>169</td>\n",
       "      <td>139</td>\n",
       "      <td>529</td>\n",
       "      <td>170</td>\n",
       "      <td>33</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N: Condition negative</th>\n",
       "      <td>1577</td>\n",
       "      <td>1720</td>\n",
       "      <td>1629</td>\n",
       "      <td>1714</td>\n",
       "      <td>1647</td>\n",
       "      <td>1677</td>\n",
       "      <td>1287</td>\n",
       "      <td>1646</td>\n",
       "      <td>1783</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test outcome positive</th>\n",
       "      <td>249</td>\n",
       "      <td>74</td>\n",
       "      <td>84</td>\n",
       "      <td>183</td>\n",
       "      <td>544</td>\n",
       "      <td>26</td>\n",
       "      <td>155</td>\n",
       "      <td>184</td>\n",
       "      <td>139</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test outcome negative</th>\n",
       "      <td>1567</td>\n",
       "      <td>1742</td>\n",
       "      <td>1732</td>\n",
       "      <td>1633</td>\n",
       "      <td>1272</td>\n",
       "      <td>1790</td>\n",
       "      <td>1661</td>\n",
       "      <td>1632</td>\n",
       "      <td>1677</td>\n",
       "      <td>1638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP: True Positive</th>\n",
       "      <td>218</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN: True Negative</th>\n",
       "      <td>1546</td>\n",
       "      <td>1707</td>\n",
       "      <td>1545</td>\n",
       "      <td>1545</td>\n",
       "      <td>1111</td>\n",
       "      <td>1652</td>\n",
       "      <td>1136</td>\n",
       "      <td>1463</td>\n",
       "      <td>1645</td>\n",
       "      <td>1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP: False Positive</th>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>84</td>\n",
       "      <td>169</td>\n",
       "      <td>536</td>\n",
       "      <td>25</td>\n",
       "      <td>151</td>\n",
       "      <td>183</td>\n",
       "      <td>138</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN: False Negative</th>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>187</td>\n",
       "      <td>88</td>\n",
       "      <td>161</td>\n",
       "      <td>138</td>\n",
       "      <td>525</td>\n",
       "      <td>169</td>\n",
       "      <td>32</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR: (Sensitivity, hit rate, recall)</th>\n",
       "      <td>0.912134</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.0473373</td>\n",
       "      <td>0.00719424</td>\n",
       "      <td>0.00756144</td>\n",
       "      <td>0.00588235</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.00657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR=SPC: (Specificity)</th>\n",
       "      <td>0.980342</td>\n",
       "      <td>0.992442</td>\n",
       "      <td>0.948435</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>0.67456</td>\n",
       "      <td>0.985092</td>\n",
       "      <td>0.882673</td>\n",
       "      <td>0.888821</td>\n",
       "      <td>0.922602</td>\n",
       "      <td>0.89363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV: Pos Pred Value (Precision)</th>\n",
       "      <td>0.875502</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0765027</td>\n",
       "      <td>0.0147059</td>\n",
       "      <td>0.0384615</td>\n",
       "      <td>0.0258065</td>\n",
       "      <td>0.00543478</td>\n",
       "      <td>0.00719424</td>\n",
       "      <td>0.00561798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV: Neg Pred Value</th>\n",
       "      <td>0.986599</td>\n",
       "      <td>0.979908</td>\n",
       "      <td>0.892032</td>\n",
       "      <td>0.946111</td>\n",
       "      <td>0.873428</td>\n",
       "      <td>0.922905</td>\n",
       "      <td>0.683925</td>\n",
       "      <td>0.896446</td>\n",
       "      <td>0.980918</td>\n",
       "      <td>0.907814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR: False-out</th>\n",
       "      <td>0.0196576</td>\n",
       "      <td>0.00755814</td>\n",
       "      <td>0.0515654</td>\n",
       "      <td>0.0985998</td>\n",
       "      <td>0.32544</td>\n",
       "      <td>0.0149076</td>\n",
       "      <td>0.117327</td>\n",
       "      <td>0.111179</td>\n",
       "      <td>0.0773976</td>\n",
       "      <td>0.10637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDR: False Discovery Rate</th>\n",
       "      <td>0.124498</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923497</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.994382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR: Miss Rate</th>\n",
       "      <td>0.0878661</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.952663</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.992439</td>\n",
       "      <td>0.994118</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.993421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACC: Accuracy</th>\n",
       "      <td>0.971366</td>\n",
       "      <td>0.973568</td>\n",
       "      <td>0.850771</td>\n",
       "      <td>0.85848</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>0.910242</td>\n",
       "      <td>0.627753</td>\n",
       "      <td>0.806167</td>\n",
       "      <td>0.906388</td>\n",
       "      <td>0.819383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0982456</td>\n",
       "      <td>0.0224404</td>\n",
       "      <td>0.0121212</td>\n",
       "      <td>0.0116959</td>\n",
       "      <td>0.00564972</td>\n",
       "      <td>0.0116279</td>\n",
       "      <td>0.00606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC: Matthews correlation coefficient</th>\n",
       "      <td>0.877157</td>\n",
       "      <td>0.710594</td>\n",
       "      <td>-0.074615</td>\n",
       "      <td>0.0295661</td>\n",
       "      <td>-0.176381</td>\n",
       "      <td>-0.0172625</td>\n",
       "      <td>-0.178498</td>\n",
       "      <td>-0.101644</td>\n",
       "      <td>-0.0236608</td>\n",
       "      <td>-0.0929446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Informedness</th>\n",
       "      <td>0.892476</td>\n",
       "      <td>0.627859</td>\n",
       "      <td>-0.0515654</td>\n",
       "      <td>0.0386551</td>\n",
       "      <td>-0.278103</td>\n",
       "      <td>-0.00771333</td>\n",
       "      <td>-0.109766</td>\n",
       "      <td>-0.105296</td>\n",
       "      <td>-0.0470946</td>\n",
       "      <td>-0.0997912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Markedness</th>\n",
       "      <td>0.862101</td>\n",
       "      <td>0.804232</td>\n",
       "      <td>-0.107968</td>\n",
       "      <td>0.0226142</td>\n",
       "      <td>-0.111866</td>\n",
       "      <td>-0.0386334</td>\n",
       "      <td>-0.290268</td>\n",
       "      <td>-0.0981191</td>\n",
       "      <td>-0.0118874</td>\n",
       "      <td>-0.0865676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>0.131608</td>\n",
       "      <td>0.0528634</td>\n",
       "      <td>0.102974</td>\n",
       "      <td>0.0561674</td>\n",
       "      <td>0.0930617</td>\n",
       "      <td>0.0765419</td>\n",
       "      <td>0.2913</td>\n",
       "      <td>0.0936123</td>\n",
       "      <td>0.0181718</td>\n",
       "      <td>0.0837004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR+: Positive likelihood ratio</th>\n",
       "      <td>46.4011</td>\n",
       "      <td>84.0705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.39204</td>\n",
       "      <td>0.145456</td>\n",
       "      <td>0.48259</td>\n",
       "      <td>0.0644475</td>\n",
       "      <td>0.052909</td>\n",
       "      <td>0.391524</td>\n",
       "      <td>0.0618495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR-: Negative likelihood ratio</th>\n",
       "      <td>0.089628</td>\n",
       "      <td>0.36736</td>\n",
       "      <td>1.05437</td>\n",
       "      <td>0.957117</td>\n",
       "      <td>1.41227</td>\n",
       "      <td>1.00783</td>\n",
       "      <td>1.12436</td>\n",
       "      <td>1.11847</td>\n",
       "      <td>1.05105</td>\n",
       "      <td>1.11167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOR: Diagnostic odds ratio</th>\n",
       "      <td>517.708</td>\n",
       "      <td>228.851</td>\n",
       "      <td>0</td>\n",
       "      <td>1.45441</td>\n",
       "      <td>0.102994</td>\n",
       "      <td>0.478841</td>\n",
       "      <td>0.0573195</td>\n",
       "      <td>0.0473049</td>\n",
       "      <td>0.372509</td>\n",
       "      <td>0.0556366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOR: False omission rate</th>\n",
       "      <td>0.0134014</td>\n",
       "      <td>0.0200918</td>\n",
       "      <td>0.107968</td>\n",
       "      <td>0.0538885</td>\n",
       "      <td>0.126572</td>\n",
       "      <td>0.077095</td>\n",
       "      <td>0.316075</td>\n",
       "      <td>0.103554</td>\n",
       "      <td>0.0190817</td>\n",
       "      <td>0.0921856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classes                               Bacterial_spot Early_blight Late_blight  \\\n",
       "Population                                      1816         1816        1816   \n",
       "P: Condition positive                            239           96         187   \n",
       "N: Condition negative                           1577         1720        1629   \n",
       "Test outcome positive                            249           74          84   \n",
       "Test outcome negative                           1567         1742        1732   \n",
       "TP: True Positive                                218           61           0   \n",
       "TN: True Negative                               1546         1707        1545   \n",
       "FP: False Positive                                31           13          84   \n",
       "FN: False Negative                                21           35         187   \n",
       "TPR: (Sensitivity, hit rate, recall)        0.912134     0.635417           0   \n",
       "TNR=SPC: (Specificity)                      0.980342     0.992442    0.948435   \n",
       "PPV: Pos Pred Value (Precision)             0.875502     0.824324           0   \n",
       "NPV: Neg Pred Value                         0.986599     0.979908    0.892032   \n",
       "FPR: False-out                             0.0196576   0.00755814   0.0515654   \n",
       "FDR: False Discovery Rate                   0.124498     0.175676           1   \n",
       "FNR: Miss Rate                             0.0878661     0.364583           1   \n",
       "ACC: Accuracy                               0.971366     0.973568    0.850771   \n",
       "F1 score                                    0.893443     0.717647           0   \n",
       "MCC: Matthews correlation coefficient       0.877157     0.710594   -0.074615   \n",
       "Informedness                                0.892476     0.627859  -0.0515654   \n",
       "Markedness                                  0.862101     0.804232   -0.107968   \n",
       "Prevalence                                  0.131608    0.0528634    0.102974   \n",
       "LR+: Positive likelihood ratio               46.4011      84.0705           0   \n",
       "LR-: Negative likelihood ratio              0.089628      0.36736     1.05437   \n",
       "DOR: Diagnostic odds ratio                   517.708      228.851           0   \n",
       "FOR: False omission rate                   0.0134014    0.0200918    0.107968   \n",
       "\n",
       "Classes                                Leaf_Mold Septoria_leaf_spot  \\\n",
       "Population                                  1816               1816   \n",
       "P: Condition positive                        102                169   \n",
       "N: Condition negative                       1714               1647   \n",
       "Test outcome positive                        183                544   \n",
       "Test outcome negative                       1633               1272   \n",
       "TP: True Positive                             14                  8   \n",
       "TN: True Negative                           1545               1111   \n",
       "FP: False Positive                           169                536   \n",
       "FN: False Negative                            88                161   \n",
       "TPR: (Sensitivity, hit rate, recall)    0.137255          0.0473373   \n",
       "TNR=SPC: (Specificity)                    0.9014            0.67456   \n",
       "PPV: Pos Pred Value (Precision)        0.0765027          0.0147059   \n",
       "NPV: Neg Pred Value                     0.946111           0.873428   \n",
       "FPR: False-out                         0.0985998            0.32544   \n",
       "FDR: False Discovery Rate               0.923497           0.985294   \n",
       "FNR: Miss Rate                          0.862745           0.952663   \n",
       "ACC: Accuracy                            0.85848           0.616189   \n",
       "F1 score                               0.0982456          0.0224404   \n",
       "MCC: Matthews correlation coefficient  0.0295661          -0.176381   \n",
       "Informedness                           0.0386551          -0.278103   \n",
       "Markedness                             0.0226142          -0.111866   \n",
       "Prevalence                             0.0561674          0.0930617   \n",
       "LR+: Positive likelihood ratio           1.39204           0.145456   \n",
       "LR-: Negative likelihood ratio          0.957117            1.41227   \n",
       "DOR: Diagnostic odds ratio               1.45441           0.102994   \n",
       "FOR: False omission rate               0.0538885           0.126572   \n",
       "\n",
       "Classes                               Target_Spot Yellow_Leaf_Curl  \\\n",
       "Population                                   1816             1816   \n",
       "P: Condition positive                         139              529   \n",
       "N: Condition negative                        1677             1287   \n",
       "Test outcome positive                          26              155   \n",
       "Test outcome negative                        1790             1661   \n",
       "TP: True Positive                               1                4   \n",
       "TN: True Negative                            1652             1136   \n",
       "FP: False Positive                             25              151   \n",
       "FN: False Negative                            138              525   \n",
       "TPR: (Sensitivity, hit rate, recall)   0.00719424       0.00756144   \n",
       "TNR=SPC: (Specificity)                   0.985092         0.882673   \n",
       "PPV: Pos Pred Value (Precision)         0.0384615        0.0258065   \n",
       "NPV: Neg Pred Value                      0.922905         0.683925   \n",
       "FPR: False-out                          0.0149076         0.117327   \n",
       "FDR: False Discovery Rate                0.961538         0.974194   \n",
       "FNR: Miss Rate                           0.992806         0.992439   \n",
       "ACC: Accuracy                            0.910242         0.627753   \n",
       "F1 score                                0.0121212        0.0116959   \n",
       "MCC: Matthews correlation coefficient  -0.0172625        -0.178498   \n",
       "Informedness                          -0.00771333        -0.109766   \n",
       "Markedness                             -0.0386334        -0.290268   \n",
       "Prevalence                              0.0765419           0.2913   \n",
       "LR+: Positive likelihood ratio            0.48259        0.0644475   \n",
       "LR-: Negative likelihood ratio            1.00783          1.12436   \n",
       "DOR: Diagnostic odds ratio               0.478841        0.0573195   \n",
       "FOR: False omission rate                 0.077095         0.316075   \n",
       "\n",
       "Classes                                   healthy mosaic_virus spider_mite  \n",
       "Population                                   1816         1816        1816  \n",
       "P: Condition positive                         170           33         152  \n",
       "N: Condition negative                        1646         1783        1664  \n",
       "Test outcome positive                         184          139         178  \n",
       "Test outcome negative                        1632         1677        1638  \n",
       "TP: True Positive                               1            1           1  \n",
       "TN: True Negative                            1463         1645        1487  \n",
       "FP: False Positive                            183          138         177  \n",
       "FN: False Negative                            169           32         151  \n",
       "TPR: (Sensitivity, hit rate, recall)   0.00588235     0.030303  0.00657895  \n",
       "TNR=SPC: (Specificity)                   0.888821     0.922602     0.89363  \n",
       "PPV: Pos Pred Value (Precision)        0.00543478   0.00719424  0.00561798  \n",
       "NPV: Neg Pred Value                      0.896446     0.980918    0.907814  \n",
       "FPR: False-out                           0.111179    0.0773976     0.10637  \n",
       "FDR: False Discovery Rate                0.994565     0.992806    0.994382  \n",
       "FNR: Miss Rate                           0.994118     0.969697    0.993421  \n",
       "ACC: Accuracy                            0.806167     0.906388    0.819383  \n",
       "F1 score                               0.00564972    0.0116279  0.00606061  \n",
       "MCC: Matthews correlation coefficient   -0.101644   -0.0236608  -0.0929446  \n",
       "Informedness                            -0.105296   -0.0470946  -0.0997912  \n",
       "Markedness                             -0.0981191   -0.0118874  -0.0865676  \n",
       "Prevalence                              0.0936123    0.0181718   0.0837004  \n",
       "LR+: Positive likelihood ratio           0.052909     0.391524   0.0618495  \n",
       "LR-: Negative likelihood ratio            1.11847      1.05105     1.11167  \n",
       "DOR: Diagnostic odds ratio              0.0473049     0.372509   0.0556366  \n",
       "FOR: False omission rate                 0.103554    0.0190817   0.0921856  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix.stats_class.to_csv(\"./Results/confusion_matrix_report.csv\")\n",
    "confusion_matrix.stats_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and Accuracy for each of the Classes in the Dataset\n",
    "\n",
    "## \tBacterial_spot\n",
    "#### True Positive Rate(Sensitivity) - 0.912134\n",
    "#### True Negative Rate(Specificity) - 0.980342\n",
    "#### Accuracy - 0.971366\t\t\n",
    "\n",
    "## \tEarly_blight\n",
    "#### True Positive Rate(Sensitivity) - 0.635417\t\n",
    "#### True Negative Rate(Specificity) - 0.992442\n",
    "#### Accuracy - 0.973568\t\t\n",
    "\n",
    "## \tLate_blight\n",
    "#### True Positive Rate(Sensitivity) - 0\n",
    "#### True Negative Rate(Specificity) - 0.948435\t\n",
    "#### Accuracy - 0.850771\t\t\n",
    "\n",
    "## \tLeaf_Mold\n",
    "#### True Positive Rate(Sensitivity) - 0.137255\t\n",
    "#### True Negative Rate(Specificity) - 0.9014\t\n",
    "#### Accuracy - 0.85848\t\t\n",
    "\n",
    "## \tSeptoria_leaf_spot\n",
    "#### True Positive Rate(Sensitivity) - 0.0473373\t\n",
    "#### True Negative Rate(Specificity) - 0.67456\t\n",
    "#### Accuracy - 0.616189\n",
    "\n",
    "## \tTarget_spot\n",
    "#### True Positive Rate(Sensitivity) - \t0.00719424\n",
    "#### True Negative Rate(Specificity) - 0.985092\t\n",
    "#### Accuracy - 0.910242\t\t\n",
    "\n",
    "## \tYellow_Leaf_Curl\t\n",
    "#### True Positive Rate(Sensitivity) - 0.00756144\n",
    "#### True Negative Rate(Specificity) - 0.882673\n",
    "#### Accuracy - 0.627753\t\t\n",
    "\n",
    "## \tHealthy\n",
    "#### True Positive Rate(Sensitivity) - \t0.00588235\t\n",
    "#### True Negative Rate(Specificity) - 0.888821\n",
    "#### Accuracy - 0.806167\n",
    "\n",
    "## \tMosaic virus\n",
    "#### True Positive Rate(Sensitivity) - 0.030303\n",
    "#### True Negative Rate(Specificity) - 0.922602\n",
    "#### Accuracy - 0.906388\t\n",
    "\n",
    "## \tSpider mite\n",
    "#### True Positive Rate(Sensitivity) - 0.00657895\n",
    "#### True Negative Rate(Specificity) - 0.89363\n",
    "#### Accuracy - 0.819383\n",
    "\n",
    "\n",
    "## Other statistics\n",
    "#### Kappa Statistics - 0.07430898197435461\n",
    "#### P-Value - 0.9999999999999999\n",
    "#### Overall accuracy -  0.17015418502202642\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
