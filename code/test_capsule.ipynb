{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: h5py in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (5.1.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.17.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-gpu==1.14.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.24.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.17.2)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.1.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: setuptools in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (41.4.0)\n",
      "Requirement already satisfied: h5py in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: opencv-python in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (4.2.0.32)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from opencv-python) (1.17.2)\n",
      "Requirement already satisfied: imutils in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (0.5.3)\n"
     ]
    }
   ],
   "source": [
    "#Downloaing the necessary libraries\n",
    "!pip install keras==2.2.4\n",
    "!pip install tensorflow-gpu==1.14.0\n",
    "!pip install opencv-python\n",
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#importint the necessary lirbraries\n",
    "\n",
    "#import tensorflow.keras as kerasfrom __future__ import print_function\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from os import listdir\n",
    "import os\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.4', '1.14.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "    return scale * x\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1\n",
    "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
    "\n",
    "class Capsule(Layer):\n",
    "    def __init__(self,\n",
    "                 num_capsule,\n",
    "                 dim_capsule,\n",
    "                 routings=3,\n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
    "        but replace b = b + <u,v> with b = <u,v>.\n",
    "\n",
    "        This change can improve the feature representation of Capsule.\n",
    "\n",
    "        However, you can replace\n",
    "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        with\n",
    "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        to realize a standard routing.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#defining the network\n",
    "#building the model\n",
    "input_image = Input(shape=(224, 224, 3))\n",
    "\n",
    "'''\n",
    "x = Conv2D(64, (3, 3), activation='relu')(input_image)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = Reshape((-1, 128))(x)\n",
    "capsule = Capsule(10, 16, 3, True)(x)\n",
    "'''\n",
    "\n",
    "x = Convolution2D(256, 11, strides = (4,4), padding = 'valid', input_shape = (224,224,3), activation = 'relu')(input_image)\n",
    "x = Convolution2D(256, 11, strides = (4,4), padding = 'valid', input_shape = (224,224,3), activation = 'relu')(input_image)\n",
    "x = Reshape((-1, 256))(x)\n",
    "capsule = Capsule(10, 16, 3, True)(x)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "classifier = Model(inputs=input_image, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now rewriting the algorithm to preprocess about 500 images in my own pipeline\n",
    "#only do this if you have enough RAM\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None\n",
    "\n",
    "image_list = np.array([])\n",
    "\n",
    "directory_root = '../dataset/train'\n",
    "imagePaths = list(paths.list_images(directory_root))\n",
    "imagePaths = imagePaths[0:-1:6]\n",
    "random.shuffle(imagePaths)\n",
    "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "\n",
    "batch_size = 16\n",
    "try:\n",
    "    for i in np.arange(0, len(imagePaths), batch_size):\n",
    "        batchPaths = imagePaths[i:i + batch_size]\n",
    "        batchLabels = labels[i: i + batch_size]\n",
    "        \n",
    "        for image in batchPaths:\n",
    "            image_list.append(convert_image_to_array(image))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "len(image_list), len(labels)\n",
    "\n",
    "np_image_list = np.array(image_list, dtype = np.float16) / 255.0\n",
    "print(f\"[INFO] splitting data\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_weights('../models/best_weights_capsule.hdf5')\n",
    "classifier.save(\"../models/test_capsule_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = '../models/best_weights_capsule_unresized.hdf5'\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1, save_best_only=True,save_weights_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "classifier.fit(x_train, y_train, batch_size = 8, epochs = 30, validation_data=(x_test, y_test), shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18160 images belonging to 10 classes.\n",
      "Found 4585 images belonging to 10 classes.\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 665s 586ms/step - loss: 3.6421 - acc: 0.0936 - val_loss: 3.6416 - val_acc: 0.0929\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.09288, saving model to ../models/best_weights_capsule_unresized.hdf5\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 587s 517ms/step - loss: 3.4478 - acc: 0.0874 - val_loss: 3.6428 - val_acc: 0.0948\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.09288 to 0.09477, saving model to ../models/best_weights_capsule_unresized.hdf5\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 599s 528ms/step - loss: nan - acc: 0.1036 - val_loss: nan - val_acc: 0.0932\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.09477\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 596s 525ms/step - loss: nan - acc: 0.1171 - val_loss: nan - val_acc: 0.0924\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.09477\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 592s 522ms/step - loss: nan - acc: 0.1171 - val_loss: nan - val_acc: 0.0928\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.09477\n",
      "Epoch 6/100\n",
      " 986/1135 [=========================>....] - ETA: 1:09 - loss: nan - acc: 0.1178"
     ]
    }
   ],
   "source": [
    "#now to  build a custom pipeline\n",
    "classifier.compile(optimizer = optimizers.SGD(lr=0.001, momentum = 0.9, decay = 0.005), loss=margin_loss, metrics=['accuracy'])\n",
    "train_datagen = ImageDataGenerator(rescale= 1./255, shear_range=0.2, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='nearest')\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 16\n",
    "base_dir = \"../dataset\"\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(base_dir+'/train', target_size=(224,224),batch_size = batch_size, class_mode='categorical')\n",
    "valid_set = valid_datagen.flow_from_directory(base_dir+'/valid', target_size=(224,224),batch_size = batch_size, class_mode='categorical')\n",
    "\n",
    "class_dict = training_set.class_indices\n",
    "li = list(class_dict)\n",
    "\n",
    "training_num = training_set.samples\n",
    "valid_num = valid_set.samples\n",
    "\n",
    "weight_path = '../models/best_weights_capsule_unresized.hdf5'\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_acc', verbose=1, save_best_only=True,save_weights_only=False, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = classifier.fit_generator(training_set, steps_per_epoch=training_num//batch_size, epochs=100,validation_data=valid_set, validation_steps=valid_num//batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now rewriting the algorithm to preprocess about 500 images in my own pipeline\n",
    "#only do this if you have enough RAM\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None\n",
    "\n",
    "image_list = np.array([])\n",
    "\n",
    "directory_root = '../dataset/train'\n",
    "imagePaths = list(paths.list_images(directory_root))\n",
    "imagePaths = imagePaths[0:-1:3]\n",
    "random.shuffle(imagePaths)\n",
    "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "\n",
    "batch_size = 16\n",
    "try:\n",
    "    for i in np.arange(0, len(imagePaths), batch_size):\n",
    "        batchPaths = imagePaths[i:i + batch_size]\n",
    "        batchLabels = labels[i: i + batch_size]\n",
    "        \n",
    "        for image in batchPaths:\n",
    "            image_list.append(convert_image_to_array(image))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "len(image_list), len(labels)\n",
    "\n",
    "np_image_list = np.array(image_list, dtype = np.float16) / 255.0\n",
    "print(f\"[INFO] splitting data\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, labels, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = classifier.history.history['acc']\n",
    "val_acc = classifier.history.history['val_acc']\n",
    "loss = classifier.history.history['loss']\n",
    "val_loss = classifier.history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "#accuracy plot\n",
    "plt.plot(epochs, acc, color='green', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.savefig('./Plots/Accuracy_Capsulenet_Colored_unresized.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss plot\n",
    "plt.plot(epochs, loss, color='blue', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, color='red', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('./Plots/Loss_Capsulenet_Colored_unresized.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the weights from saved\n",
    "classifier.load_weights(\"../models/best_weights_capsule_unresized.hdf5\")\n",
    "y_pred = []\n",
    "for i in range(0, x_test.shape[0]):\n",
    "    img = np.expand_dims(x_test[i], axis=0)\n",
    "    prediction, y_recon = classifier.predict(img)\n",
    "    li = [\"Bacterial_spot\", \"Early_blight\",\"healthy\", \"Late_blight\", \"Leaf_Mold\", \"mosaic_virus\", \"Septoria_leaf_spot\", \"spider_mite\",\"Target_Spot\",\"Yellow_Leaf_Curl\"] \n",
    "    class_name = li[prediction.argmax()]\n",
    "    y_pred.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the confusion matrix and evaluating the predictions\n",
    "confusion_matrix = ConfusionMatrix(y_test_unclassfied, y_pred)\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.to_dataframe().to_csv(\"./Results/confusion_matrix_colored.csv\")\n",
    "confusion_matrix.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.stats_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.stats_class.to_csv(\"./Results/confusion_matrix_report.csv\")\n",
    "confusion_matrix.stats_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
