{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: h5py in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (5.1.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.17.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-gpu==1.14.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.24.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.17.2)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.1.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: setuptools in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (41.4.0)\n",
      "Requirement already satisfied: h5py in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: opencv-python in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (4.2.0.32)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (from opencv-python) (1.17.2)\n",
      "Requirement already satisfied: imutils in /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages (0.5.3)\n"
     ]
    }
   ],
   "source": [
    "#Downloaing the necessary libraries\n",
    "!pip install keras==2.2.4\n",
    "!pip install tensorflow-gpu==1.14.0\n",
    "!pip install opencv-python\n",
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importint the necessary lirbraries\n",
    "\n",
    "#import tensorflow.keras as kerasfrom __future__ import print_function\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from os import listdir\n",
    "import os\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.4', '1.14.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "    return scale * x\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1\n",
    "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
    "\n",
    "class Capsule(Layer):\n",
    "    def __init__(self,\n",
    "                 num_capsule,\n",
    "                 dim_capsule,\n",
    "                 routings=3,\n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
    "        but replace b = b + <u,v> with b = <u,v>.\n",
    "\n",
    "        This change can improve the feature representation of Capsule.\n",
    "\n",
    "        However, you can replace\n",
    "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        with\n",
    "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        to realize a standard routing.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/michael/anaconda3/envs/tensorlow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#building the model\n",
    "input_image = Input(shape=(224, 224, 3))\n",
    "\n",
    "'''\n",
    "x = Conv2D(64, (3, 3), activation='relu')(input_image)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = Reshape((-1, 128))(x)\n",
    "capsule = Capsule(10, 16, 3, True)(x)\n",
    "'''\n",
    "\n",
    "x = Convolution2D(96, 11, strides = (4,4), padding = 'valid', input_shape = (224,224,3), activation = 'relu')(input_image)\n",
    "x = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = \"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#second convolution set\n",
    "x = Convolution2D(256, 11, strides = (1,1), padding = \"valid\", activation = \"relu\")(x)\n",
    "x = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = \"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#third convolution set\n",
    "x = Convolution2D(384, 3, strides = (1,1), padding = \"valid\", activation = \"relu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#fourth convolution set\n",
    "x = Convolution2D(384, 3, strides = (1,1), padding = \"valid\", activation = \"relu\")(X)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#fifth convolution set\n",
    "x = Convolution2D(256, 3, strides = (1,1), padding = \"valid\", activation = \"relu\")(x)\n",
    "x = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = \"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#flattening step\n",
    "x = Flatten()(x)\n",
    "\n",
    "#dense network\n",
    "x = Dense(units = 4096, activation = \"relu\")(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(units = 4096, activation = \"relu\")(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(units = 1000, activation = 'relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#x = Dense(units = 10, activation = \"softmax\"))\n",
    "x = Reshape((-1, 128))(x)\n",
    "capsule = Capsule(10, 16, 3, True)(x)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "classifier = Model(inputs=input_image, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now rewriting the algorithm to preprocess about 500 images in my own pipeline\n",
    "#only do this if you have enough RAM\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None\n",
    "\n",
    "image_list = np.array([])\n",
    "\n",
    "directory_root = '../dataset/train'\n",
    "imagePaths = list(paths.list_images(directory_root))\n",
    "imagePaths = imagePaths[0:-1:3]\n",
    "random.shuffle(imagePaths)\n",
    "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "\n",
    "batch_size = 16\n",
    "try:\n",
    "    for i in np.arange(0, len(imagePaths), batch_size):\n",
    "        batchPaths = imagePaths[i:i + batch_size]\n",
    "        batchLabels = labels[i: i + batch_size]\n",
    "        \n",
    "        for image in batchPaths:\n",
    "            image_list.append(convert_image_to_array(image))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "len(image_list), len(labels)\n",
    "\n",
    "np_image_list = np.array(image_list, dtype = np.float16) / 255.0\n",
    "print(f\"[INFO] splitting data\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = '../models/best_weights_capsule.hdf5'\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1, save_best_only=True,save_weights_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "classifier.fit(x_train, y_train, batch_size = 8, epochs = 30, validation_data=(x_test, y_test), shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18160 images belonging to 10 classes.\n",
      "Found 4585 images belonging to 10 classes.\n",
      "Epoch 1/25\n",
      "1318/2270 [================>.............] - ETA: 21:19 - loss: 3.6449 - acc: 0.0892"
     ]
    }
   ],
   "source": [
    "#now to  build a custom pipeline\n",
    "classifier.compile(optimizer = optimizers.SGD(lr=0.001, momentum = 0.9, decay = 0.005), loss=margin_loss, metrics=['accuracy'])\n",
    "train_datagen = ImageDataGenerator(rescale= 1./255, shear_range=0.2, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='nearest')\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 8\n",
    "base_dir = \"../dataset\"\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(base_dir+'/train', target_size=(224,224),batch_size = batch_size, class_mode='categorical')\n",
    "valid_set = valid_datagen.flow_from_directory(base_dir+'/valid', target_size=(224,224),batch_size = batch_size, class_mode='categorical')\n",
    "\n",
    "class_dict = training_set.class_indices\n",
    "li = list(class_dict)\n",
    "\n",
    "training_num = training_set.samples\n",
    "valid_num = valid_set.samples\n",
    "\n",
    "weight_path = '../models/best_weights_capsule.hdf5'\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1, save_best_only=True,save_weights_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = classifier.fit_generator(training_set, steps_per_epoch=training_num//batch_size, epochs=25, validation_steps=valid_num//batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
